Topical Word Trigger Model for Keyphrase Extraction 


Z hi y u a n L i u 	C he n L i a n g 	M a os o n g S un 
 Department of Computer Science and Technology 
State Key Lab on Intelligent Technology and Systems National Lab for Information Science and Technology 
     Tsinghua University, Beijing 100084, China 
ßÐÞÝºØ Ù¸  	ÒÐ Ò º ÖÖÝ _ Ñ ÐºÓÑ¸ ×Ñ×_Ø× Ò 	Ùº 	ÙºÒ 

AB S T R A C T 
Keyphrase extraction aims to find representative phrases for a document. Keyphrases are 
expected to cover main themes of a document. Meanwhile, keyphrases do not necessar- ily occur frequently in the document, which is known as the vocabulary gap between the words in a document and its keyphrases. In this paper, we propose Topical Word Trigger Model (TWTM) for keyphrase extraction. TWTM assumes the content and keyphrases of a document are talking about the same themes but written in different languages. Under the assumption, keyphrase extraction is modeled as a translation process from document content to keyphrases. Moreover, in order to better cover document themes, TWTM sets trig- ger probabilities to be topic-specific, and hence the trigger process can be in?uenced by the document themes. On one hand, TWTM uses latent topics to model document themes and takes the coverage of document themes into consideration; on the other hand, TWTM uses topic-specific word trigger to bridge the vocabulary gap between the words in document and keyphrases. Experiment results on real world dataset reveal that TWTM outperforms existing state-of-the-art methods under various evaluation metrics. 

TI T L E 

AND 

AB S T R A C T 

IN 

CH I N E S E 

Ù Ã  Ù º 1/2³  

³ Ã áî¿Ù³Ý ¬û èãÄ ¬ù Ý 

" ß ¤1/4 Ã 

ù¿Ù Ã  Ù º TðT³ 1/2¬¨ ³ ¬Ì WM 

º

Âðè 

³ ³ Ñ 

¬ËÆÐ³¬³¿ O Ð­6 ÙÄ Ä ¬Oª 9ßÃè¿¬ßÃ Ì º Ù 

Î ðßÃ ³ 

Ã Ã"ò¸àà ÌÌºº õÃ 

Ã³ ¬ Ã 1/2 ª Ð­³ ¬ Ã ¿ Ü 

¿ O è ´Â Ä Ì º Ù Ë¨ 

³

Ù àß ¬ 


KEYWORDS: keyphrase extraction, latent topic model, word trigger model. 
KE Y W O R D S I N CH I N E S E: ³ 	,	õ Ã º Ù º ,	.



Proceedings of COLING 2012: Technical Papers, pages 1715-1730, 
                      COLING 2012, Mumbai, December 2012. 
1715 

1	Introduction 
For information retrieval and management, people usually annotate a collection of 
keyphrases to a document as its brief summary. Keyphrases can be found in most digital libraries and information retrieval systems (Turney, 2000; Nguyen and Kan, 2007). Web information, most of which is in the form of text, is growing at a rapid rate. For the large volume of documents, it will be inefficient for human editors to manually index keyphrases. Therefore, automatically extracting keyphrases for documents is proposed as a challenging 
task in natural language processing. The task is also referred to as keyphrase extraction. 
When we enter Web 2.0 era, social tagging is invented to help users manage and share 
information. The social tags can be regarded as a type of keyphrases. Various methods have been proposed for automatic social tag suggestion, which can be regarded as a special type of keyphrase extraction. In social tag suggestion, given a document, the system will select keyphrases from a controlled tag list instead of document itself. It indicates that keyphrases do not necessarily occur in the given document. It is obvious that it provides a more ?exible and convenient scheme compared to traditional keyphrase extraction, and thus becomes the main application of keyphrase extraction. In this paper, we will focus on the new setting of keyphrase extraction, which is named as keyphrase extraction from a controlled vocabulary. In the following paper, unless specifically noted, we use keyphrase extraction as referred to the new setting. 
As a summary of document, keyphrases are expected to represent and cover the main 
themes of the given document. Suppose there is an article talking about the "Apple" com- pany and its smartphone "iPhone". The extracted keyphrases are expected to cover the both themes, i.e., "Apple" and "iPhone". This indicates that a set of keyphrases that focuses on only one theme will not be adequate. Meanwhile, representative keyphrases do not nec- essarily occur frequently in the document. Take the article for example again, it may men- tion "iPhone" (smartphone of Apple), "iPad" (tablet computer of Apple) and "Steve Jobs" (founder of Apple) for many times, but refer to "Apple" not so frequently. Nevertheless, it is intuitive that "Apple" should be a representative keyphrase of the document. We refer the phenomenon as a vocabulary gap between words in document and keyphrases. In summary, given a document, keyphrase extraction should: (1) find a set of representative keyphrases that can better cover the main themes of the document. (2) The selection of keyphrases should primarily rely on their semantic relatedness with the document rather than being constrained by their occurrence frequencies in the document. This requires keyphrase ex- traction can bridge the vocabulary gap between document content and keyphrases. 
Many unsupervised methods have also been extensively explored for keyphrase extrac- 
tion. The most simple unsupervised method is ranking the candidate keyphrases according to TFIDF (Salton and Buckley, 1988) and then selecting top-ranked ones as keyphrases. There are also graph-based methods (Mihalcea and Tarau, 2004; Wan and Xiao, 2008b,a; Liu et al., 2010), clustering-based methods (Grineva et al., 2009; Liu et al., 2009) and la- tent topic models (Heinrich, 2005; Blei and Lafferty, 2009) proposed for keyphrase extrac- tion. Most of these methods take frequencies of candidate keyphrases as the crucial de- cision criteria, and thus tend to select those high-frequency ones as keyphrases. Given sufficient annotation data for training, we can adopt the classification-based approach for keyphrase extraction. For example, some methods (Frank et al., 1999; Witten et al., 1999; Turney, 2000) regard keyphrase extraction as a binary classification problem (is-keyphrase 



1716 

or non-keyphrase). Keyphrase extraction can also be considered as a multi-label classifi- 
cation problem (Tsoumakas and Katakis, 2007), in which each keyphrase is regarded as a category label. Various methods such as Naive Bayes (Garg and Weber, 2008) and kNN (Li et al., 2009) have been explored. Some researchers proposed using latent topics to build semantic relations between words and tags. The representative methods include TagLDA (Krestel et al., 2009; Si and Sun, 2009) and Content Relevance Model (CRM) (Iwata et al., 2009). However, these methods usually suffer from the over-generalization problem. 
Recently, a new approach based on word alignment models (WAM) in statistical machine 
translation (SMT) has been proposed for keyphrase extraction (Ravi et al., 2010; Liu et al., 2011b,a, 2012). WAM-based methods assume the content and keyphrases of a document are describing the same themes but written in different languages. Under this assump- tion, WAM-based methods regard keyphrase extraction as a translation process from doc- ument content to keyphrases. This process is modeled as a trigger from important words in document content to keyphrases according to trigger probabilities between words and keyphrases. WAM-based methods will learn trigger probabilities from sufficient document- keyphrase pairs. With the trigger probabilities, given a novel document, WAM-based meth- ods are able to extract relevant keyphrases that do not necessarily occur so frequently in the document. 
Although achieving significant improvement in bridging the vocabulary gap between docu- 
ment and keyphrases, WAM-based methods, however, cannot well guarantee the coverage of document themes. The crucial reason is analyzed as follows. WAM-based methods, for- malizing trigger probabilities at word level, consider each single word in document and project from document content to keyphrases. However, the coverage of document themes 
should be appreciated at topic level, which is beyond the power of WAM-based methods. 
A promising approach for representing document themes is latent topic models (Blei et al., 
2003). In topic models, both words/keyphrases and documents are represented as proba- 
bilistic distributions over latent topics. Topic models are widely adopted as a guaranteed 
approach to represent document themes. Topic models themselves can also be used for keyphrase extraction, referred to as topic-based methods, by simply ranking keyphrases according to their semantic relevance with the document themes in terms of latent topics. Topic-based methods can be regarded as a trigger process at topic level, contrast to the trigger process at word level in WAM-based methods. Since common keyphrases receive larger probabilities given a topic, topic-based methods tend to select those keyphrases that are too general to tightly capture the main themes of the document. For example, it may select "IT" as keyphrase for the above mentioned document, which is so general that cannot re?ect the document themes well. 
Is there a way to leverage the power of both word-level projection and topic-level coverage 
in keyphrase extraction? Can the two techniques, i.e., word alignment models and latent topic models, be integrated together to complement each other for keyphrase extraction? To address the problems, we propose Topical Word Trigger Model (TWTM) for keyphrase extraction. TWTM inherits the advantage of WAM-based methods, and also incorporates latent topic models so as to promise the coverage of document themes. 
To compare and analyze the characteristics of different approaches for keyphrase extraction, 
we also introduce the method based on word alignment models, i.e., Word Trigger Model (WTM), and the method based on polylingual topic models, i.e., Topic Trigger Model (TTM). 



1717 

As these names suggest, WTM identifies keyphrases by triggering at word level; while TTM 
triggering at topic level. TWTM, integrating their advantages, performs both word-level and topic-level triggers to extract keyphrases. 
To demonstrate the effectiveness of our method, we carry out experiments on a real-world 
dataset crawled from a website with keyphrases having been annotated collaboratively by users. Experiment results show that TWTM can identify appropriate keyphrases with better coverage of document themes compared to existing WAM-based methods. 
2	Our Method 
In this section we first introduce two simple trigger methods, WTM and TTM, in which 
WTM performs triggering at word level while TTM at topic level. Afterwards, we introduce our method TWTM. 













(a) WTM 	(b) TTM 	(c) TWTM 
                  Figure 1: Trigger Models for keyphrase extraction. 
               
2.1 Notations and Definitions 
Before introducing baselines and our method, we give some notations. We denote a docu- 

ment as d?? D, where D is the doccument set. For each document d, we kdenote its content 

as a sequence of words c =??ci?N=1 and its keyphrases as a set k =??ki?N=1. The vocabulary 

i

i

of words in documents is denoted as W , and the vocabulary of keyphrases as V . Each word 

ci in documents is an instance of a word type w in W , i.e., ci = w?? W ; each keyphrase ki 

of documents is an instance of a keyphrase type v in V , i.e., ki = v?? V . 
We define keyphrase extraction as follows. Given a document d with its content c, 
keyphrase extraction aims to seek a set of keyphrases k that maximizes Pr(k?c). By simply as- 

suming the keyphrases are independent conditional over d, we have Pr(k?c) = k?k Pr(k?c). The optimal set of keyphrases k? can be represented as follows: 


k? = arg max Pr(k?c) = arg max 


Pr(k?c). 


(1) 

k

k

k??k 

Suppose the number of keyphrases is pre-defined as N k, we can simply find k? by ranking 



1718 


selecting top-N k keyphrases. each candidate keyphrase v?? V according to its score Pr(v?c) in descending order and 

2.2 Word Trigger Model 
Word Trigger Model (WTM) is inspired by IBM Model-1 (Brown et al., 1993), the most 
widely used word alignment models in SMT. WTM assumes the content and the keyphrases of a document are describing the same themes while written in two different languages: document content in one language while keyphrases in the other. From this perspective, keyphrase extraction can be regarded as a translation process from a given document con- tent to keyphrases. 
In more detail, the translation process is modeled as a trigger process as follows. First, WTM 
finds several important words in the document content as trigger words. Then, activated by these trigger words, WTM maps the document content into keyphrases. A trigger in the translation process can be regarded as a mapping function from the words in document to keyphrases. 
WTM formalizes a trigger as a hidden variable a. By assuming each keyphrase of a docu- 
ment is triggered by only one word in the content, a a maps each keyphrase at position j 
(i.e., kj) as triggered by a word at position i in document content c (i.e., ci), denoted as 
aj = i. Given a document, its content c and keyphrases k can be connected by a trigger 
variable a. The probability of triggering k from c can be formalized as 


Pr(k?c) = 



a


Pr(k, a?c) = 



a


Pr(k?a, c) Pr(a?c). 


(2) 

Following the same assumptions of IBM Model-1 (Brown et al., 1993), for each document 


from c as follows: d?? D, WTM assumes the content c of d already exists, and the keyphrases k are generated 

  1. For each document d with content c and N k keyphrases: 
      (a) For j from 1 to N k: 
            i. Sample each word trigger link aj from 1, . . . , N c according to a uniform dis- 
   tribution. 
           ii. Sample each kj = v according to trigger probability Pr(kj = v?caj = w, ?). 
                        
Here we denote the trigger probability from a word w?? W to a keyphrase v?? V as 

?vw = Pr(v?w), and the trigger probabilities from W to V form a matrix ?. The corre- sponding graphical representation is shown in Figure 1a. The boxes are "plates" represent- 
ing replicates. In this graphical model, the variables k and c are shaded indicating that they are observed; while the unshaded variables, including a and ?, are latent (i.e., unobserved). 
Under the same assumptions of IBM Model-1, we write 

        Nk 	Nc 	Nk 	Nc 
1	1

Pr(k?c)???


(N c)(Nk) 


j=1 i=1 

Pr(kj = v?ci = w) = 


(N c )(Nk) 


j=1 i=1 

?v w . 

(3) 


for learning. WTM has global optimum, and is efficient and easily scalable to large training We see that, in WTM, trigger probabilities ?vw = Pr(kj = v?ci = w) are the key parameters 



1719 

data. We use Expectation-Maximization (EM) (Dempster et al., 1977) to estimate trigger 
probabilities ?. 
Using the estimated ?, when given a novel document d with its content c, we can rank 
each candidate keyphrase v as follows: 


Pr(v?c) = 



w??c 


Pr(v?w, ?) Pr(w?c) = 



w??c 


?vw Pr(w?c), 


(4) 


where Pr(w?c) indicates the weight of the word w in c, which can be calculated using the TFIDF score of w in c. From the ranking list in descending order, we can select the top- 
ranked ones as keyphrases of the given document. 

2.3 Topic Trigger Model 
WTM triggers keyphrases at the word level. We can also trigger at the topic level, and 
thus propose Topic Trigger Model (TTM) for keyphrase extraction. TTM is inspired by Polylingual Topic Models (Mimno et al., 2009), which is originally proposed to model par- allel documents in multiple languages. TTM is an extension of latent Dirichlet allocation (LDA) (Blei et al., 2003). 


by users. TTM assumes that the content c and keyphrases k of a document d share the Suppose there are T latent topics in TTM, and the number of topics??T?? can be pre-defined 
same distribution over??T?? topics (i.e., ?d ), which is drawn from a symmetric Dirichlet prior 

to two different multinomial distributions over words, one for keyphrases (i.e., ?k) and 

with concentration parameter ?. TTM also assumes that each topic t?? T corresponds t
another for content (i.e., ?ct), each of which is drawn from a specific symmetric Dirichlet 
with concentration parameter, ? k or ? c. TTM can be viewed as a generative process of both 
document content and keyphrases as follows: 

   1. Sample word distribution ?ct from Dirichlet(? c) and sample keyphrase distribution 
   
?k from Dirichlet(? k) for each topic t?? T . t

2. For each document d?? D with N c words and N k keyphrases: 
(a) Sample topic distribution ?d from Dirichlet(?). 
(b) For i from 1 to N c 
         i. Sample a topic zi = t from M ul t inomial(?d). 
         
           ii. Sample a word ci = w according to multinomial distribution Pr(ci = w?zi = t , ? c ). 
      (c) For j from 1 to N k 
 i. Sample a topic zj = t from M ul t inomial(?d). 
           ii. Sample a keyphrase kj = v according to multinomial distribution Pr(kj = 
              v?zj = t, ?k). 
The corresponding graphical model is shown in Figure 1b, where the observed variables 
(i.e., words c, keyphrases k and hyper-parameters ? k and ? c) are shaded. 
Given the observed words in a collection of documents, the task of TTM learning is to com- 
pute the posterior distribution of the latent topic assignments z, the topic mixtures ?d of 



1720 

each document d, and the distributions over words ?ct and ?k of each topic t. By assum- t
ing a Dirichlet prior ? on ?, ? can be integrated according to the Dirichlet-multinomial 
conjugacy. In this paper, we use Gibbs Sampling to estimate parameters, which has been 
widely used as an inference method for many latent topic models. In Gibbs sampling, it is usual to integrate out the mixtures ? and topics ? and just sample the latent variables z. 
The process is thus called collapsed. 
Gibbs Sampling iteratively performs latent topic assignments for each word in the document 

set, and estimates the distributions over words of each topic (i.e., ?cwt = Pr(ci = w?zi = t) 

and ?kt = Pr(kj = v?zj = t)), and the distribution over topics of each document (i.e., v

?td = Pr(zi = t?d)). Take a word token ci = w in d for example, given the current state of all but the variable zi, the conditional probability of zi = t is 


Pr(zi = t?ci = w, c?i, z?i, k)???


N c ,? i + ? c wt 


N??di + ? t


,


(5) 

N c?? 1 +??W??? c t

?

N c + N k?? 1 +?? T??? 

d

d

where z is the current topic assignments for all tokens in the document set; N c t is the w

number of occurrences of word w that are assigned with topic t; N c is the number of t
occurrences of all words that are assigned with topic t; Ntd is the number of occurrences 

of topic t assigned in the current document d; N c and N k are the numbers of all tokens in 

d

d


position i. the content and keyphrases of d, respectively;??i indicates taking no account of the current 


assignment zi of the ci in d. Whenever zi of ci is assigned with a new topic drawn from According to the posterior probability Pr(zi = t?ci = w, c?i , z?i, k), we re-sample the topic 

Equation (5), N c t and Ntd are updated. We perform topic assignments in the same way for w
each word ki in k of d. After enough sampling iterations to burn in the Markov chain, ?c, 
?k and ? are estimated as follows: 

                       Nc t + ?c 
                                    
?cwt = 

w

,

? kt = 

N kt + ? k v

,

?t d = 

Nt d + ? 

.

(6) 

Nc t

+??W??? c 

v

N k +?? V??? k t

N c + N k +?? T??? 

d

d

When finishing the learning process, we obtain the distributions over words of each topic, 
i.e., ?k and ?c. Suppose we are asked to extract keyphrases from a novel document with 
only content c. First, we infer topic assignments for each word in c with Gibbs Sampling. 
With the topic assignments, we summarize the distribution over topics of the content c as 

                                              N cd + ? 
                                              
Pr(t?c) = 
  
t
N c +?? T??? d

.

(7) 

Triggered by the topics of c, we rank each candidate keyphrase v?? V as follows: 

Pr(v?c) = 


t??T 

Pr(v?t, ?k) Pr(t?c) = 


t??T 

? kt ? t d , v

(8) 

and then select the top-ranked as keyphrases of the given document. 

2.4 Topical Word Trigger Model 
WTM and TTM perform trigger operations at either word or topic level. WTM addresses 
the problem of vocabulary gap between documents and keyphrases, and can thus suggest 



1721 

keyphrases that are uncommon or even not showing up in the given document. TTM, on the 
other hand, takes the main themes of the given document in consideration when extracting keyphrases. In order to aggregate the advantages of the both methods, extended from WTM and TTM, we propose Topical Word Trigger Model (TWTM) for keyphrase extraction. 
Similar to TTM, TWTM also assumes that topics are sampled at the word level. Each doc- 
ument is represented as a multinomial distribution over T latent topics. On the document 

content side, each topic t?? T corresponds to a multinomial distribution over words, which 

is similar to TTM. On the keyphrase side, each topic t?? T corresponds to a topic-specific 

content and keyphrases is as follows: translation table ?t . Given each document d?? D, the generative process of both document 


1. Sample word distribution ?ct from Dirichlet(? c) for each topic t?? T . 

2. Sample keyphrase distribution ?tw from Dirichlet(? k) for each topic t?? T and each 
   word w?? W . 
   
3. For each document d?? D with N c words and N k keyphrases: 
(a) Sample topic distribution ?d from Dirichlet(?). 
(b) For i from 1 to N c 
         i. Sample a topic zi = t from M ul t inomial(?d). 
         
           ii. Sample a word ci = w according to multinomial distribution Pr(ci = w?zi = t , ? c ). 
      (c) For j from 1 to N k 
 i. Sample a topic zj = t from M ul t inomial(?d). 
           ii. Sample each word trigger link aj from all words in d that are generated 
   from t according to a uniform distribution. 
           iii. Sample each kj = v according to trigger probability Pr(kj = v?caj = w, ?t ). 
The graphical model is shown in Figure 1c. Topic-dependent translation probabilities ?t 
are the key parameters. Each ?t maintains the translation probability from each word 

ci = w in contents to each keyphrase kj = v under topic t, i.e., ?tvw = Pr(kj = v?ci = w, t). 
Given the observed words and keyphrases in a collection of documents, the task of TWTM 
learning is to compute the posterior distribution of the latent topic assignments z, the topic 
mixtures ?d of each document d, the distribution over words ?t of each topic t, and the 
trigger probabilities ?t of each topic t. We can also use Gibbs Sampling to estimate pa- 
rameters in TWTM. On the document content side, we can perform topic assignments z 
for each word as in TTM using Equation (5). On the keyphrase side, the problem is more 
complicated. Suppose we will assign each keyphrase kj with a topic zj and a trigger aj. 
Take a keyphrase kj = v for example, given the current state of all but the variable zj and 
aj, the conditional probability of zj = t, aj = i is calculated as follows, 


Pr(zj = t, aj = i?kj = v, k?j, z?j, a?j, ci = w, c)???


  N t,w?j + ? k v
Nwt ? 1 +?? V??? k 


?


   N??dj + ? t
Nd?? 1 +??T??? 


,


(9) 

where z is the current topic assignments for all translation pairs in the document set; N tw v

is the number of occurrences that w is translated to v given topic t; Nw is the number of t
occurrences of word w in all translation pairs given topic t; Ntd is the number of occurrences 
of topic t assigned in the current document d; Nd is the number of all translation pairs in 



1722 


the conditional probability of zj = t, aj = i, we formalize the marginal probability of zj = t the current document d;?? j also indicates taking no account of the current position j. Given 
as follows, 

Nc 	N t,c?j + ? k 

Pr(zj = t?kj = v, k?j, z?j, a?j, c)???


i=1 Nci t

vi 
? 1 +?? V??? 

?
   
N??dj + ? t
Nd?? 1 +??T??? 

.

(10) 

After re-assigning the topic zj = t for the current keyphrase according to Equation (10), we 
can further compute the trigger probability as follows: 

                                                           N t,c?j + ? 
                                                           
P r ( a j = i??z j = t , k j = v, k?? j , z?? j , a?? j , c ) = 
    
vi 
Ncti?? 1 +??V??? k 

.

(11) 

According to Equation (11), we re-assign trigger word ci for the current keyphrase kj. After 
enough sampling iterations to burn in the Markov chain, ?c, ?t and ? are estimated as 
follows: 

Nwt + ? c

c

Nvw + ? t

Nt d + ? 

?cwt = 

N c +??W??? c t

,

?tvw = 

Nwt +??V??? 

,

?t d = 

N k + N c +?? T??? 

.

(12) 

d

d


larger than ? in WTM, and thus faces more serious problem of data sparsity. To remedy The potential size of topical trigger probabilities ? is??V????W????T??. The size is comparative 
the problem, we use interpolation smoothing technique for ? of TWTM. In this paper, we 
employ smoothing using ? of WTM as follows: 

Pr SMOOTH (v?w, t) = ? Pr TW T M (v?w, t) + (1?? ?) Pr W T M (v?w, t), 	(13) 
where Pr SMOOTH (v?w, t) is the smoothed topical trigger probabilities, Pr TW T M (v?w, t) is the 

original topical trigger probabilities of TWTM, Pr W T M (v?w, t) is the trigger probabilities of 


be reduced to non-topic trigger probabilities; and when ? = 1.0, there will be no smoothing WTM. ? is the smoothing factor ranging from 0.0 to 1.0. When ? = 0.0, Pr tSMOOTH (v?w) will 

in Pr SMOOTH (v?w, t). 
In TWTM, we perform keyphrase extraction as follows. Suppose we need perform 
keyphrase extraction for a document d with its content c. We perform Gibbs Sampling 
to iteratively estimate the topic distribution of d (i.e., ?d ) according to document content 
c. Afterwards, we select N k keyphrases using the ranking score of each keyphrase v: 


P r ( v??c ) = 



w??c t?? T 


Pr(v?w, t) Pr(w?c) Pr(t?c) = 



w??c t?? T 


?tvw?td Pr(w?c), 


(14) 

where Pr(w?c) is the weight of the word w in document content c, which can be estimated 

by the TFIDF score of w in c; Pr(t??d ) is the probability of the topic t given the document d. 
3	Experiments and Analysis 
3.1 Dataset and Experiment Setting 
To evaluate the performance of TWTM for keyphrase extraction, we carry out experiments 
on a real world dataset, crawled from ÓÙ ÒºÓÑ, the largest product review website in 
China. Each product contains a description which is considered as a document content, and 
also contains a set of keyphrases annotated by users collaboratively which are considered 



1723 

as standard keyphrases. The dataset consists of annotations for three types of products, i.e., 

book, movie and music. The statistics of the dataset is shown in Table 1, where??D?,??W??, 

?V??, N c and N k are the number of documents, the vocabulary of contents, the vocabulary of 





keyphrases, the average number of words and keyphrases in each document, respectively. In Table 1, we use DOUBAN to represent the whole dataset and use BOOK, MOVIE and MUSIC to show the statistics for instances for different product types. 


  D a ta 
DOUBAN 
B OOK 
MOVIE MUSIC 



71, 525 ? D??
26, 807 
18, 933 25, 785 



160, 276 ?W???
81, 846 
86, 339 
106, 523 



99, 457 ?V???
41, 199 
37, 034 31, 228 


 Nc 
8 6 .3 0 
8 3 .1 3 
8 6 .0 4 8 9 .7 7 


 Nk 
1 0 .5 3 
 8 .9 5 
1 6 .0 3 
 8 .1 3 
 
 
                      Table 1: Statistical information of dataset. 
To evaluate the performance of our method and compare with other methods, we randomly 
select 1, 000 instances from each of three types of products to form the test set with 3, 000 instances, and use the rest of the dataset as training set. 
In our experiments we select three evaluation metrics. The first metric is precision, recall 
and F-measure represented as p = ccorrect /cextract , r = ccorrect /cstandard and F = 2pr/(p+r), 
where ccorrect is the total number of keyphrases that are correctly suggested by a method, 
cextract is the total number of automatic extracted keyphrases, and cstandard is the total 
number of human-labeled standard keyphrases. 
In fact, ranking order of extracted keyphrases also indicates the performance of different 
methods. A method is regarded better than another one if it ranks correct keyphrases higher. 
However, precision/recall/F-measure does not take the order of extracted keyphrases into 
account. To address the problem, we select the following two additional metrics. One met- 
ric is binary preference measure (Bpref) (Buckley and Voorhees, 2004). Bpref can consider the order of extracted keyphrases for evaluation. For a document, if there are R correct keyphrases within M extracted keyphrases by a method, in which r is a correct keyphrase 

and n is an incorrect keyphrase. It is defined as Bpref = 1 r?R 1????n ranked hiMgher than r? . R
The other metric is mean reciprocal rank (MRR) (Voorhees, 2000) which is usually used to 
evaluate how the first correct keyphrase for each document is ranked. For a document d, 
rankd is denoted as the rank of the first correct keyphrase with all extracted keyphrases, It 

is defined as MRR =??1? d?D ra1kd , where D is the document set for keyphrase extraction. 

                           D
                  
3.2 Case Studies 

n

Before quantitative evaluation, we perform case studies by looking into the topics learned 
by TWTM. By setting T = 100 of TWTM, We select two topics, i.e., Topic-59 and Topic-92 
for study. In first several rows of Table 2, we list the top-10 words and top-10 keyphrases 

given the two topics separately (i.e., ranked by Pr(w?t) and Pr(v?t)). From the top words and keyphrases, we can conclude that Topic-59 is about "art design" and Topic-92 is about 
"computer programming". 
What will the topics in?uence the trigger probabilities? We pick a word "graphics" for ex- 
ample. In the context of the topic "art design", the word "graphics" always correlates with "design", "color" and "art"; while in the context of the topic "computer programming", the 



1724 

word "graphics" generally refers to "computer graphics" and thus correlates to "program- 
ming", "software" and "programming language". At the bottom of Table 2, we show the top-6 keyphrases triggered by the word "graphics" with respect to the two topics. The value 

in the bracket after each keyphrase v is the probability ?tvw = Pr(v?w, t), which is the top- ical specific trigger probability from w (here is the word "graphics") to v under the topic 
t. From the top triggered keyphrases by "graphics" under two topics, we can see they are discriminative with each other, and have intense topic characteristics. 

                 Topic-59 	Topic-92 
Top 	Words 	Keyphrases 	Words 	Keyphrases 
 1	design 	design 	program 	computer 
2	creativity creativity 	develop 	program 
3	designer 	designing 	application software engineer 
4	magazine handcraft 	object 	C++ 
5	fashion 	graphic design 	technology programming 
6	game 	fashion 	design 	program design 
7	work 	game 	s ys t e m 	program develop 
8	color 	product design 	function 	Linux 
9	vision 	industrial design 	software 	computer science 
10 	advertise 	magazine 	method 	Alan 

graphics 

design (0.482) 
color science (0.089) 
font design (0.084) 
product design (0.077) 
landscape design (0.050) 
art design (0.039) 

game programming (0.201) 
programming language (0.107) 
Web 2.0 (0.094) 
C (0.078) 
Linux (0.077) 
Computer Graphics (0.049) 


                   Table 2: Examples of topics learned with TWTM. 
After investigating the topics, we look into keyphrase extraction results given a product 
description. Here we select a Japanese classical literature The Tale of Genji for example, which was written by Murasaki Shikibu in the early years of the 11th century 1. The book recounts the life and love stories of a son of the Japanese emperor. In Table 3, we show the 

top-10 keyphrases extracted by WTM, TTM and TWTM, in which we use (?) to highlight the inappropriate keyphrases. 


Method WTM 

T TM 

TWTM 


                             Extracted Keyphrases 
The Tale of Genji, classic, Japan, foreign literature, Murasaki Shikibu, politics (-), love, 
political science (-), eason (-), political philosophy (-) 
novel, Japan, foreign literature, history, love, sociology (-), culture, literature, Russia 
(-), female (-) 
novel, foreign literature, The Tale of Genji, history, Japan, classic, literature, love, 
Murasaki Shikibu, politics (-) 


        Table 3: Examples of extracted keyphrases for the book The Tale of Genji. 
From Table 3 we observe that: (1) WTM can suggest keyphrases that are closely related to 
the book, such as "The Tale of Genji" and "Murasaki Shikibu". However, due to not consider- ing document themes, WTM will extract irrelevant keyphrases such as "politics", "political 


1


ØÔ "" ÒºÛ 


Ô


ºÓÖ "Û 


"Ì 


ÌÐ 


Ó


Ò. 




1725 

science", "eason" and "political philosophy". (2) TTM triggers keyphrases with the favor of 
latent topics, which are usually too general to commendably represent the document main themes. We can see TTM fail to extract specific keyphrases such as "The Tale of Genji" and "Murasaki Shikibu". What is worse, TTM over-generalizes the document themes and ex- tract inappropriate keyphrases "sociology", "'Russia" and "female". (3) Taking advantages of both WTM and TTM, TWTM can extract specific and representative keyphrases and at the same time guarantee the coverage of document themes. We can see that TWTM achieves a smart balance between word-level projections and topic-level coverage. 

3.3 Parameter In?uences 

There are two crucial parameters in TWTM, the number of topics T and the smoothing factor ?. In Table 4 and Table 5, we demonstrate the performance of TWTM for keyphrase 
extraction when parameters change. 

 T	Precision 	Recall 	F-measure 	Bpref 	MRR 10 	0 .3 1 3 	0 .3 0 4 	0 .3 0 9 	0 .3 1 3 	0 .8 2 5 
30 	0 .3 3 7 	0 .3 2 5 	0 .3 3 1 	0 .3 3 7 	0 .8 3 7 50 	0 .3 3 9 	0 .3 2 9 	0 .3 3 4 	0 .3 3 9 	0 .8 2 7 70 	0 .3 5 1 	0 .3 3 9 	0 .3 4 5 	0 .3 5 1 	0.840 100 	0.354 	0.343 	0.349 	0.354 	0 .8 3 8 

Table 4: The in?uence of topic number T of TWTM for keyphrase extraction when N k = 10 
and smoothing factor ? = 0.4. 

 ?	Precision 	Recall 	F-measure 	Bpref 	MRR 0 .0 	0 .3 1 0 	0 .2 5 4 	0 .2 7 9 	0 .3 1 0 	0 .6 7 6 
0 .2 	0 .3 1 8 	0 .3 1 4 	0 .3 1 6 	0 .3 1 8 	0 .8 2 3 0 .4 	0 .3 5 4 	0 .3 4 3 	0 .3 4 9 	0 .3 5 4 	0.838 0 .6 	0.364 	0.349 	0.357 	0.364 	0 .8 1 2 0 .8 	0 .3 5 0 	0 .3 3 4 	0 .3 4 2 	0 .3 5 1 	0 .7 6 4 1 .0 	0 .3 2 3 	0 .3 0 6 	0 .3 1 4 	0 .3 2 4 	0 .7 3 1 

Table 5: The in?uence of smooth factor ? of TWTM for keyphrase extraction when N k = 10 
and the number of topics T = 100. 

From Table 4, we can see that, as the number of topics T increases from T = 10 to T = 100, 
the performance roughly improves. This indicates that the granularity of topics will in?u- 
ence the keyphrase extraction performance. When T = 70 and T = 100, the performance 
achieves a relatively stable good status. Hence, when comparing TWTM with other meth- 
ods, we set T = 100 for TWTM. 

As shown in Table 5, when the smoothing factor is set with ? = 0.4 or ? = 0.6, TWTM 
achieves the relatively best performance. When either ? = 0.0 (i.e., WTM), or ? = 1.0 (i.e., 
non-smoothed TWTM), the performance is much poorer compared to smoothed TWTM. 
This reveals that it is necessary to address the sparsity problem of TWTM by smoothing 
with WTM. Therefore, when comparing TWTM with other methods, we set ? = 0.4 for 
TWTM. 



1726 

3.4 Performance Comparison 
Besides WTM and TTM, we also select three representative methods as baselines for compar- 
ison: the classification-based method Naive Bayes (NB) (Garg and Weber, 2008), the topic- based method CRM (Iwata et al., 2009) and the word-projection method TAM (Si et al., 
2010). We set T = 1, 024 for CRM which achieves its best performance. 
In Figure 2 we show the precision-recall curves of NB, CRM, TAM, WTM, TTM and TWTM 
on the dataset. Each point of a precision-recall curve represents extracting different number 
of keyphrases ranging from N k = 1 (bottom right, with higher precision and lower recall) 
to N k = 10 (upper left, with higher recall but lower precision), respectively. The closer the 
curve to the upper right, the better the overall performance of the method. 

               0.35 
NB 
CRM 

 0.3 

0.25 

 0.2 

0.15 

 0.1 

0.05 

TAM WTM TTM 
TWTM 

0.2 	0.3 	0.4 	0.5 	0.6 	0.7 	0.8 
                                 Precision 
                   
               Figure 2: Precision-recall curves for keyphrase extraction. 
Figure 2 clearly shows that TWTM outperforms other methods significantly. The interesting 
phenomena is that, when N k is getting larger, the advantages of TWTM are more obvious compared to baselines. We know that when a system is asked to extract more keyphrases (i.e., N k is larger), it is becoming important for extracted keyphrase to have a good cover- age of document themes. Otherwise, the performance will drop sharply. This is the issue suffered by WTM. We can see that, although WTM is relatively excellent when suggesting top several keyphrases, it performs poor when suggesting more keyphrases due to the poor ability on ensuring coverage. 

In Table 6 we list the comparison results of various methods when extracting N k = 10 
keyphrases. We can observe that TWTM outperforms the best baseline TAM by 7% of F- 
measure. Moreover, as mentioned above, the dataset consists of three types of products. In Table 6 we also demonstrate the results of TWTM on the test instances divided by product types, denoted as "BOOK", "MOVIE" and "MUSIC". The performance is consistently decent on the three types of instances. We also observe that F-measure scores on the three types of instances are proportional to the size of their training instances as shown in Table 1. Apparently, more training instances will enhance sufficiently learning of TWTM, which may 



1727 

Method 	Precision 	Recall 	F-measure 	Bpref 	MRR 
 NB 	0 .2 8 3 	0 .2 3 2 	0 .2 5 5 	0 .2 8 3 	0 .7 0 2 
CRM 	0 .2 6 7 	0 .2 1 6 	0 .2 3 9 	0 .2 6 7 	0 .6 4 8 TAM 	0 .3 1 0 	0 .2 5 4 	0 .2 7 9 	0 .3 1 0 	0 .6 7 6 WTM 	0 .2 4 2 	0 .2 4 2 	0 .2 4 2 	0 .2 4 2 	0 .7 8 5 T TM 	0 .2 2 6 	0 .2 0 3 	0 .2 1 4 	0 .2 2 6 	0 .6 3 8 TWTM 	0.354 	0.343 	0.349 	0.354 	0.838 
B OOK 	0 .3 6 5 	0 .4 2 8 	0 .3 9 4 	0 .3 6 5 	0 .8 6 1 
MOVIE 	0 .3 5 6 	0 .2 7 4 	0 .3 1 0 	0 .3 5 6 	0 .8 2 0 MUSIC 	0 .3 4 1 	0 .3 2 6 	0 .3 3 4 	0 .3 4 1 	0 .8 3 1 

           Table 6: Comparison results when extracting N k = 10 keyphrases. 
       
also eventually improve the performance of keyphrase extraction. 
Conclusion and Future Work 

This paper focuses on keyphrase extraction from a controlled vocabulary. The proposed TWTM has two features: (1) TWTM uses latent topics to represent document themes, and thus takes the coverage of document themes into consideration; (2) TWTM models topic- specific word triggers, which are more discriminative. Hence TWTM is able to bridge the vocabulary gap between document content and keyphrases more precisely. Experiment results on real world dataset demonstrate that TWTM outperforms existing state-of-the-art methods under various evaluation metrics. We also demonstrate that TWTM achieves a balance between word-level projection and topic-level coverage. 

Moreover, TWTM is not restricted to supervised learning. TWTM can also be adopted in unsupervised fashion. So long as we can build appropriate translation pairs to represent semantic relations between documents and keyphrases, TWTM will be able to exert its capacity. For example, for news articles, we can use news titles and contents to build trans- lation pairs, by regarding titles as an approximate language to keyphrases; for scientific papers, we can use abstracts and contents to build translation pairs. 

We design the following research plans: (1) The number of topics in TWTM requires be- ing pre-defined by users. We plan to incorporate Bayes Nonparametric (Blei et al., 2010) for TWTM to automatically learn the number of topics. (2) The trigger probabilities in TWTM do not take rich linguistic knowledge into consideration. We plan to incorporate more complicated alignment models from SMT into our model. (3) This paper focuses on supervised learning of TWTM. We plan to investigate unsupervised learning of TWTM for documents such as news articles and scientific papers. (4) The in?uence of product types for keyphrase extraction has not been thoroughly investigated in this paper. We plan to study the impact of product types and explore domain adaptation (Blitzer et al., 2006) for cross-domain keyphrase extraction using TWTM. 
Acknowledgments 

This work is supported by the National Natural Science Foundation of China (NSFC) under the grant No. 61170196 and 61202140. The authors would like to thank Douban Inc. for providing the anonymized data. 



1728 

References 
Blei, D., Griffiths, T., and Jordan, M. (2010). The nested chinese restaurant process and 
bayesian nonparametric inference of topic hierarchies. Journal of the ACM, 57(2):7. 

Blei, D. and Lafferty, J. (2009). Text mining: Classification, Clustering, and Applications, chapter Topic models. Chapman & Hall. 

Blei, D., Ng, A., and Jordan, M. (2003). Latent dirichlet allocation. Journal of Machine 
Learning Research, 3:993-1022. 

Blitzer, J., McDonald, R., and Pereira, F. (2006). Domain adaptation with structural corre- spondence learning. In Proceedings of EMNLP, pages 120-128. 

Brown, P., Pietra, V., Pietra, S., and Mercer, R. (1993). The mathematics of statistical machine translation: Parameter estimation. Computational linguistics, 19(2):263-311. 

Buckley, C. and Voorhees, E. (2004). Retrieval evaluation with incomplete information. In Proceedings of SIGIR, pages 25-32. 

Dempster, A., Laird, N., Rubin, D., et al. (1977). Maximum likelihood from incomplete data via the em algorithm. Journal of the Royal Statistical Society. Series B (Methodological), 39(1):1-38. 

Frank, E., Paynter, G., Witten, I., Gutwin, C., and Nevill-Manning, C. (1999). Domain- specific keyphrase extraction. In Proceedings of IJCAI, pages 668-673. 

Garg, N. and Weber, I. (2008). Personalized, interactive tag recommendation for ?ickr. In Proceedings of RecSys, pages 67-74. 

Grineva, M., Grinev, M., and Lizorkin, D. (2009). Extracting key terms from noisy and multi-theme documents. In Proceedings of WWW, pages 661-670. 

Heinrich, G. (2005). Parameter estimation for text analysis. Web: http://www. arbylon. 
net/publications/text-est. 
Iwata, T., Yamada, T., and Ueda, N. (2009). Modeling social annotation data with content 
relevance using a topic model. In Proceedings of NIPS, pages 835-843. 

Krestel, R., Fankhauser, P., and Nejdl, W. (2009). Latent dirichlet allocation for tag recom- mendation. In Proceedings of ACM RecSys, pages 61-68. 

Li, X., Snoek, C., and Worring, M. (2009). Learning social tag relevance by neighbor voting. IEEE Transactions on Multimedia, 11(7):1310-1322. 

Liu, Z., Chen, X., and Sun, M. (2011a). A simple word trigger method for social tag suggestion. In Proceedings of EMNLP, pages 1577-1588. 

Liu, Z., Chen, X., and Sun, M. (2012). Mining the interests of chinese microbloggers via keyword extraction. Frontiers of Computer Science, 6(1):76-87. 

Liu, Z., Chen, X., Zheng, Y., and Sun, M. (2011b). Automatic keyphrase extraction by bridging vocabulary gap. In Proceedings of CoNLL, pages 135-144. 



1729 

Liu, Z., Huang, W., Zheng, Y., and Sun, M. (2010). Automatic keyphrase extraction via 
topic decomposition. In Proceedings of EMNLP, pages 366-376. 
Liu, Z., Li, P., Zheng, Y., and Sun, M. (2009). Clustering to find exemplar terms for 
keyphrase extraction. In Proceedings of EMNLP, pages 257-266. 
Mihalcea, R. and Tarau, P. (2004). Textrank: Bringing order into texts. In Proceedings of 
EMNLP, pages 404-411. 
Mimno, D., Wallach, H., Naradowsky, J., Smith, D., and McCallum, A. (2009). Polylingual 
topic models. In Proceedings of EMNLP, pages 880-889. 
Nguyen, T. and Kan, M. (2007). Keyphrase extraction in scientific publications. In Pro- 
ceedings of the 10th International Conference on Asian Digital Libraries, pages 317-326. 
Ravi, S., Broder, A., Gabrilovich, E., Josifovski, V., Pandey, S., and Pang, B. (2010). Au- 
tomatic generation of bid phrases for online advertising. In Proceedings of WSDM, pages 341-350. 
Salton, G. and Buckley, C. (1988). Term-weighting approaches in automatic text retrieval. 
Information processing and management, 24(5):513-523. 
Si, X., Liu, Z., and Sun, M. (2010). Modeling social annotations via latent reason identifi- 
cation. IEEE Intelligent Systems, 25(6):42-49. 
Si, X. and Sun, M. (2009). Tag-LDA for scalable real-time tag recommendation. Journal 
of Computational Information Systems, 6(1):23-31. 
Tsoumakas, G. and Katakis, I. (2007). Multi-label classification: An overview. International 
Journal of Data Warehousing and Mining (IJDWM), 3(3):1-13. 
Turney, P. (2000). Learning algorithms for keyphrase extraction. Information Retrieval, 
2(4):303-336. 
Voorhees, E. (2000). The trec-8 question answering track report. In Proceedings of TREC, 
pages 77-82. 
Wan, X. and Xiao, J. (2008a). Collabrank: towards a collaborative approach to single- 
document keyphrase extraction. In Proceedings of COLING, pages 969-976. 
Wan, X. and Xiao, J. (2008b). Single document keyphrase extraction using neighborhood 
knowledge. In Proceedings of AAAI, pages 855-860. 
Witten, I., Paynter, G., Frank, E., Gutwin, C., and Nevill-Manning, C. (1999). Kea: Practical 
automatic keyphrase extraction. In Proceedings of DL, pages 254-255. 









1730 
