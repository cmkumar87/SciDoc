 UNPMC: Na¨ive Approach to Extract Keyphrases from Scientific Articles

            Jungyeul Park                            Jong Gun Lee                            Beatrice Daille´
                   LINA,                              LIP6-CNRS,                                  LINA,
         Universite´ de Nantes                      UPMC (Paris 6)                       Universite´ de Nantes
             Nantes, France                           Paris, France                           Nantes, France
         jungyeul.park                              jonggun.lee                          beatrice.daille
       @univ-nantes.fr                                 @lip6.fr                          @univ-nantes.fr


                         Abstract                                  The task of extracting key phrases would be
                                                                considered as a subtask of extracting terminology
    We describe our method for extracting                       if key phrases are a kind of terms. Typical ap-
    keyphrases from scientific articles which                   proaches for automatically extracting terms use
    we participate in the shared task of                        linguistic preprocessing which involves morpho-
    SemEval-2 Evaluation Exercise.                Even          syntactic analysis such as part-of-speech tagging
    though general-purpose term extractors                      and phrase chunking, and statistical postprocess-
    along with linguistically-motivated analy-                  ing such as log likelihood which compares the
    sis allow us to extract elaborated morpho-                  term frequencies in a document against their ex-
    syntactic variation forms of terms, a na¨ive                pected frequencies derived in a bigger text. Be-
    statistic approach proposed in this paper                   sides, extracting terms prefers syntactically plau-
    is very simple and quite efficient for ex-                  sible noun phrases (NPs) which are mainly multi-
    tracting keyphrases especially from well-                   words terms. Kim and Kan (2009) report that most
    structured scientific articles.         Based on            of key phrases are often simple words than less of-
    the characteristics of keyphrases with sec-                 ten compound words2.
    tion information, we obtain 18.34% for                         The task for extracting key phrases tend to in-
    f-measure using top 15 candidates. We                       clude analyzing the document structure. Espe-
    also show further improvement without                       cially, extracting key phrases from well-structured
    any complications and we discuss this at                    scientific articles should consider cross-section in-
    the end of the paper.                                       formation (Nguyen and Kan, 2007). This informa-
                                                                tion has been explored to assess the suitability of
1    Introduction1                                              features during learning in Kim and Kan (2009).

Key phrases are a set of words to capture the main                 Extracting key phrases, however, is more than to

topic of the document. Since key phrases con-                   extracting terminology or analyzing the document

tain the substance of the document, they are used               structure. While terms are words which appear in

in the large spectrum of areas; from applications               specific contexts and analyse concept structures in

which explicitly use key phrases such as automatic              domains of human activity, key phrases are words

indexing, documents classification and search en-               that capture the key idea of documents. In addi-

gine optimization in information retrieval, to ap-              tion, while terms usually occur in the given doc-

plications which implicitly use key phrases such as             ument more often than we would expect to occur,

summarization and question-answering systems.                   key phrases do not necessarily occur frequently or

During the last decade, many previous works have                key phrases do not occur at all in the document.

dealt with the various methods for automatically                Consequently, the task for extracting key phrases

extracting key phrases (e.g., Frank et al., 1999;               should not be considered as the subtask of extract-

Barker and Corrnacchia, 2000; Turney, 2003;                     ing terminology and we are not able to directly ap-

Medelyan and Witten, 2006; Nguyen and Kan,                      ply general-purpose term extractors to extract key

2007; Wan and Xiao, 2008).                                      phrases.
                                                                   In this paper, we describe our method for "Au-
   1UNPMC means the collaborative team from Laboratoire         tomatic Keyphrase Extraction from Scientific Ar-
d'Informatique de Nantes Atlantique of the Universit´e de
Nantes and Laboratoire d'Informatique de Paris 6 of the Uni-       2In training data, only 23.4% of keyphrases, however, are
versit´e Pierre et Marie Curie.                                 single words.


                                                            178
              Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 178­181,
                    Uppsala, Sweden, 15-16 July 2010. 2010 Association for Computational Linguisticsc

ticles", the shared task of SemEval-2 Evalua-
tion Exercise which we participated in.                     Al-                              length=1
                                                                                             (29.7%)
though term extractors along with linguistically-                                                                                        length=1
                                                                                                               length=2                  (17.7%)
                                                                                                                (53.2%)
motivated analysis allow us to extract even elab-                                                  length=4+
                                                                                                                                           length=4+
                                                                      length=2                     (4.3%)
orated morpho-syntactic variation forms of terms,                                                                                          (7.2%)
                                                                       (51.3%)
                                                                                               length=3
                                                                                               (14.7%)
the na¨ive statistic approach proposed in this pa-                                                                                length=3
                                                                                                                                  (21.8%)

per is very simple and quite efficient for extracting
keyphrases especially from well-structured scien-                           (a) D-author                             (b) D-reader
tific articles. In a nutshell, our method is based
on empirical rules without any linguistically-                    Figure 1: Word length of keyphrases in training
motivated preprocessing. Empirical rules are ob-                  data
tained from the analysis of the characteristics of
keyphrases by observing training data.                            occurrences of keyphrases of each section. Due
  The remaining of this paper is organized as fol-                to the variation of the naming of the section,
lows: Section 2 explains the characteristics of                   we divide sections into title and abstract, intro-
keyphrases in scientific articles. Section 3 and 4                duction, conclusion, and the rest including refer-
detail our na¨ive statistic approach and experiment,              ences. Table 2 and 3 show the number of occur-
respectively. We conclude this paper and discuss a                rences and the accumulative number of unique oc-
further improvement in Section 6.                                 currences of keyphrases in each section, respec-
2    Characteristics of Keyphrases in                             tively. We also show the accumulative number
     Scientific Articles                                          of words in each section in Table 4. Including
                                                                  the rest sections exponentially diminishes the ra-
In this section, we investigate the characteristics of            tio of the number of gold keyphrases to the number
keyphrases in training data. Table 1 shows statis-                of candidate keyphrases. Note that m words pro-
tics of training data. In Table 1, D-author means                 duce   Pn     -1
                                                                              i=0   (m - i) candidate keyphrases for up
the keyphrases assigned by authors, D-reader the                  to n-word keyphrases by supposing that candidate
keyphrases assigned by readers, and D-combined                    keyphrases are simple n-word terms.
the combined keyphrases assigned by both of au-                     Note also that both author- and reader-assigned
thors and readers.                                                keyphrases hold only 75.49% and 89.44%, re-
                                                                  spectively. Even some keyphrases are different
                 # of papers (p) # of key phrases (k)  k / p
    D-author          144               563            3.91       with surface forms in the document and our na¨ive
    D-reader          144               1,865         12.95
    D-combined        144               2,265         15.73       method with no linguistic intervention is not able
                                                                  to recognize them. For example, one of reader-
         Table 1: Statistics of training data                     assigned keyphrases distributed real-time embed-
                                                                  ded system for C-41 actually appears as distributed
2.1   Word length of keyphrases                                   real-time and embedded (DRE) systems.

We measure the distribution of word length of key                                                         D-author       D-reader
phrases in training data and present it in Figure 1.                           Title and Abstract                 277            802
                                                                               Introduction                       215            491
Over half of key phrases are two-word key phrases                              Conclusion                         313            982
                                                                               Other                              387          1,210
in both author- and reader-assigned key phrases.
Differently with Kim and Kan (2009) which they                    Table 2: Number of occurrences of keyphrases in
reported that most of key phrases are often sim-                  each section
ple words than less often compound words, only
29.7% and 17.7% of key phrases are one-word key                                                          D-author           D-reader
phrases. There are also more than four-word key                            Total                       563 (100.0%)      1,865 (100.0%)

phrases which hold 4.3% and 7.2% of author and                              Title and Abstract         277 (49.20%)        802 (43.00%)
                                                                              `+' Introduction         317 (56.30%)        937 (50.24%)
reader assigned key phrases, respectively.                                    `+' Conclusion           367 (65.19%)      1,311 (70.29%)
                                                                              `+' Other                425 (75.49%)      1,668 (89.44%)

2.2   Occurrences of keyphrases                                   Table 3: Accumulative number of unique occur-
In which section do keyphrases occur frequently?                  rences of keyphrases in each section
To answer this question, we count the number of


                                                               179

                          # words (W)  # gold (G)   G/W
      Title and Abstract       28435         802  0.0282              improve recall, but probably diminish preci-
        `+' Introduction       72729         937  0.0128              sion since the rest sections occupy over 70%
        `+' Conclusion        178473        1311  0.0073
        `+' Other             948007        1668  0.0018              of the document.

Table 4: Number of words in training data and                       · Almost half of keyphrases occur coinciden-
gold data (D-reader)                                                  tally in keysections and the rest sections. We
                                                                      decide that our approach limits coincident

2.3   Coincidence of keyphrases                                       keyphrases in both of them. This decision is
                                                                      made empirically and improve precision.
Figure 2 shows the coincidence of keyphrases3.
Almost half of keyphrases (58.44% and 45.74%                       The following procedure explains and details
for author- and reader-assigned keyphrases, re-                  our approach for extracting keyphrases.
spectively) occur coincidentally in keysections
and the rest sections. Keysections hold 65.19%                      · Extract up to three-word terms from keysec-

and 70.29% of keyphrases and the rest sections                        tions as candidate keyphrases.

besides keysections hold 68.74% and 64.88% of                       · Filter them out if they contain one or more of

whole keyphrases. Note that the rest sections oc-                     stop words or non-content-containing words

cupy over 70% of the document on the average.                         (see Table 5 for non-content-containing
                                                                      words).
                                                                    · Countthenumberofoccurrencesofextracted
                                                                      terms from each keysection.
                                                                    · Check the coincidence whether candidate
                                                                      keyphrases occurs in more than two keysec-
                                                                      tions. If so, we assign weight.
                                                                    · Calculate a score for candidate keyphrases
                                                                      and list them by order of the score.
       (a) D-author                   (b) D-reader
                                                                 4   Experiment results
        Figure 2: Coincidence of keyphrases                      This section shows the experiment results with
                                                                 training and test data.
3    Methodology                                                 4.1   Training data

From training data, we observe and decide the fol-               To optimize our results, we use various thresholds
lowings:                                                         for the number of n-word keyphrases and weight.
                                                                   We try to find the (i : j : k) pattern which
   · More than four-word keyphrases hold only                    means i one-word, j two-word, and K three-
      4.3% and 7.2% of whole keyphrases. We                      word keyphrases to produce the best results. We
      decide that our approach limits the word                   also try to find the threshold for weight d to cal-
      length as three for extracting keyphrases.                 culate the score as follows: if keyphrases ap-
      Thus we extract only up to three-word                      pear in more than two keysections, score =
      keyphrases. This choice might lead the per-                d  # of total occurences, otherwise score =
      formance degradation of our method because                 # of total occurences. Table 6 shows our best
      we explicitly exclude more than four-word                  results for training data where (i : j : k) = (3 :
      keyphrases.                                                9 : 3) and d = 2. Empirically, we found these
                                                                 thresholds from training data by iterating several
   · Keysections hold 65.19% and 70.29% of                       possibilities4.
      keyphrases.        We decide that our approach
      limits keysections from which we extract                   4.2   Test data
      keyphrases. Including the rest sections may                Table 7 shows our test data results published by
                                                                 organizers of the shared task of SemEval-2 Evalu-
   3We denote title and abstract as A, introduction as I, con-   ation Exercise.
clusion as C, and the rest sections including references as
Other.                                                              4These thresholds will be more examined in future work.


                                                              180

              Type           Examples
              Noun           section, abstract, introduction, conclusion, reference, future work, figure, paper, result, laboratory, university
              Verb           present, how, introduce, become, improve, find, help, improve, consider, call, yield, allow, give, assume
              Adverb         always, formally, necessarily, successfully, previously, usually,mainly, final, essentially, ultinately, commonly,
                             severely, significantly, dramatically, clearly, still, well, who, whose, whom, which, whether, therefore,
              Other POSs     that, this, those, these, many, several, more, over, less, behind, above, below, each, few, different, under,
                             both, within, through, prior, various, better, following, between, possible, via, before,even, such, if, new,
                             show, important, simple, good, tranditional, current, varying, necessary, previous, clear

                   Table 5: Example of (heuristically obtained) non-content-containing terms


      AUTHOR.STEM.FINAL                                                              Moreover, our n-word terms based extraction
      # Gold: 559    Match    Precision       Recall     F-score
      Top 05            43       5.97%        7.69%       6.72%                  can be benefited by linguistic preprocessing such
      Top 10           101       7.01%       18.07%      10.10%
      Top 15           139       6.44%       24.87%      10.23%                  as normalizing surface forms. Handcrafted regu-
                                                                                 lar expression rules along with part-of-speech tag-
      READER.STEM.FINAL
      # Gold: 1824   Match    Precision       Recall     F-score                 ging and phrase chunking would be also intro-
      Top 05           118      16.39%        6.47%       9.28%                  duced to improve candidate selection. We have
      Top 10           249      17.29%       13.65%      15.26%
      Top 15           361      16.71%       19.79%      18.12%                  not explored thoroughly feature engineering, nei-

      COMBINED.STEM.FINAL                                                        ther. For example, more fine-grained section infor-
      # Gold: 2223   Match    Precision       Recall     F-score                 mation and weight re-assignment might help filter
      Top 05           143      19.86%        6.43%       9.71%
      Top 10           309      21.46%       13.90%      16.87%                  out irrelevant candidates. We leave these possibil-
      Top 15           441      20.42%       19.84%      20.13%                  ities for future work.
             Table 6: Training data results
                                                                                 References
           READER.STEM.FINAL
          # Gold: 1204   Precision       Recall      Fscore                      Ken Barker and Nadia Cornacchia. 2000. Using noun phrase
          Top 05          13.80%         5.73%        8.10%                          heads to extract document keyphrases. In Proceedings
          Top 10          15.10%       12.54%       13.70%                           of the 13th Biennial Conference of the Canadian Soci-
          Top 15          14.47%       18.02%       16.05%                           ety on Computational Studies of Intelligence: Advances
           COMBINED.STEM.FINAL                                                       in Artificial Intelligence, pages 40-52. May 14-17, 2000.
                                                                                     Montr´eal, Quebec, Canada.
          # Gold: 1466   Precision       Recall      Fscore
          Top 05          18.00%         6.14%        9.16%
          Top 10          19.00%       12.96%       15.41%                       Eibe Frank , Gordon W. Paynter , Ian H. Witten , Carl Gutwin,
          Top 15          18.13%       18.55%       18.34%                           and Craig G. Nevill-Manning. 1999. Domain-Specific
                                                                                     Keyphrase Extraction. In Proceedings of the 16th Inter-
                Table 7: Test data results                                           national Joint Conference on Artificial Intelligence, pages
                                                                                     668-673. July 31-August 6, 1999. Stockholm, Sweden.

5    Conclusion and Discussion                                                   Su Nam Kim and Min-Yen Kan. 2009. Re-examining Auto-
                                                                                     matic Keyphrase Extraction Approaches in Scientific Ar-
In this paper, we described our simple method                                        ticles. In Proceedings of the Workshop on Multiword Ex-
                                                                                     pressions: Identification, Interpretation, Disambiguation
for extracting keyphrases from scientific arti-                                      and Applications (MWE 2009), ACL-IJCNLP 2009, pages
cles which we participate in the shared task of                                      9-12. August 6, 2009. Singapore.
SemEval-2 Evaluation Exercise. The na¨ive ap-                                    Olena Medelyan and Ian H. Witten. 2006. Thesaurus based
proach was proposed.                This approach turned                             automatic keyphrase indexing.                 In Proceedings of the
out very simple and quite efficient for extracting                                   6th ACM/IEEE-CS joint conference on Digital libraries,
                                                                                     pages 296-297. June 11-15, 2006. Chapel Hill, NC, USA.
keyphrases from well-structured scientific articles.
Based on learning the distribution of keyphrases                                 Thuy Dung Nguyen and Min-Yen Kan. 2007. Key phrase
with section information, we obtain 18.34% for f-                                    Extraction in Scientific Publications. Asian Digital Li-
                                                                                     braries. Looking Back 10 Years and Forging New Fron-
measure using top 15 candidates.                                                     tiers, pages 317-326. Springer Berlin, Heidelberg.
   Our na¨ive approach still has much room for                                   Peter D. Turney. 2003. Coherent keyphrase extraction via
improvement. For example, we are able to im-                                         Web mining. In Proceedings of the 18th International
prove the result for same test data up to 20.71%                                     Joint Conference on Artificial Intelligence, pages 434-
and 25.55% for f-measure using top 15 candidates                                     439. August 9-15, 2003. Acapulco, Mexico.

simply by adding the rest sections and normaliz-                                 Xiaojun Wan and Jianguo Xiao. 2008. CollabRank: towards
ing the number of occurrences of terms from each                                     a collaborative approach to single-document keyphrase
section5.                                                                            extraction.      In Proceedings of the 22nd International
                                                                                     Conference on Computational Linguistics (Coling 2008),
   5                                                                                 pages 969-976. 18-22 August, 2008. Manchester, UK.
    The result is not improved only by adding the rest sec-
tions.


                                                                         181

