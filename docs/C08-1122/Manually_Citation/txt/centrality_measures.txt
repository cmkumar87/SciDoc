Author manuscript, published in "International Joint Conference on Natural Language Processing (IJCNLP), Nagoya : Japan 
                                                                                 (2013)" 
                                                 
                                                             
                                                             
              A Comparison of Centrality Measures for 
                 Graph-Based Keyphrase Extraction 
                   
                   
                                 Florian Boudin 
LINA - UMR CNRS 6241, Universit´ de Nantes, France e
     florian.boudin@univ-nantes.fr 
     
        
     
     
     
            Abstract 
             
In this paper, we present and compare various centrality measures for graph- based keyphrase extraction. Through ex- periments carried out on three standard datasets of different languages and do- mains, we show that simple degree cen- trality achieve results comparable to the widely used TextRank algorithm, and that closeness centrality obtains the best results on short documents. 





methods construct a word graph from which the most important nodes are selected as keyphrases. TextRank (Mihalcea and Tarau, 2004), a ranking algorithm based on the concept of eigenvector cen- trality, is usually applied to compute the impor- tance of the nodes in the graph. Here, centrality is used to estimate the importance of a word in a document. 
  The concept of centrality in a graph has been extensively studied in the field of social network analysis and many different measures were pro- posed, see (Opsahl et al., 2010) for a review. Sur- prisingly, very few attempts have been made to ap- 
  
1

Introduction 

ply such measures to keyphrase extraction. (Lit- 

Keyphrases are the words and phrases that pre- 
cisely and compactly represent the content of a document. Keyphrases are useful for a variety of tasks such as summarization (Zha, 2002), informa- tion retrieval (Jones and Staveley, 1999) and docu- ment clustering (Han et al., 2007). However, many documents do not come with manually assigned keyphrases. This is because assigning keyphrases to documents is very costly and time consuming. As a consequence, automatic keyphrase extraction has attracted considerable attention over the last few years. 
  Previous works fall into two categories: super- 
vised and unsupervised methods. The idea behind supervised methods is to recast keyphrase extrac- 

vak et al., 2011) is one of them, where degree cen- trality is used to select keyphrases. However, they evaluate their method indirectly through a summa- rization task, and to our knowledge there are no published experiments using other centrality mea- sures for keyphrase extraction. In this study, we conduct a systematic evaluation of the most well- known centrality measures applied to the task of keyphrase extraction on three standard evaluation datasets of different languages and domains1. 
  The rest of this paper is organized as follows. We first brie?y review the previous work, followed by a description of the centrality measures. Next, we present our experiments and results and con- clude with a discussion. 
  
tion as a binary classification task (Witten et al., 1999). Unsupervised approaches proposed so far 

2

Related work 

have involved a number of techniques, including language modeling (Tomokiyo and Hurst, 2003), clustering (Liu et al., 2009) and graph-based rank- ing (Mihalcea and Tarau, 2004). While supervised approaches have generally proven more success- ful, the need for training data and the bias towards the domain on which they are trained remain two critical issues. 

Graph-based keyphrase extraction has received 
much attention recently and many different ap- proaches have been proposed (Mihalcea and Ta- rau, 2004; Wan and Xiao, 2008a; Wan and Xiao, 2008b; Liang et al., 2009; Tsatsaronis et al., 2010; Liu et al., 2010). All of these approaches use a graph representation of the documents in 

1Code 	and datasets used in this study are available 

  In this work, we focus on graph-based methods 
for keyphrase extraction. Given a document, these 

at https://github.com/boudinfl/centrality_ 
measures_ijcnlp13 


which nodes are words or phrases, and edges rep- 	3.2 	Centrality measures 

resent co-occurrence or semantic relations. The importance of each node is computed using Tex- tRank (Mihalcea and Tarau, 2004), a graph-based ranking algorithm derived from Google's PageR- ank (Page et al., 1999). Words corresponding to the top ranked nodes are then selected and assem- bled to generate keyphrases. 
  Most previous studies focus on building a more 
accurate graph representation from the content of the documents (Tsatsaronis et al., 2010) or adding features to TextRank (Liu et al., 2010), but very few tried to use other existing centrality mea- sures. The only works we are aware of are that of Litvak and Last (2008) that applied the HITS algorithm (Kleinberg, 1999), and Litvak et al. 

Once the word graph is constructed, centrality 
measures are computed to assign a score to each node. Let G = (V, E) be a graph with a set of ver- tices (nodes) V and a set of edges E. Starting with degree centrality, this section describes the rank- ing models we will be using in this study. 
  Degree centrality is defined as the number of 
edges incident upon a node. Applied to a word 
graph, the degree of a node Vi represents the num- 
ber of words that co-occur with the word corre- 
sponding to Vi. Let?? (Vi) be the set of nodes 
connected to Vi, the degree centrality of a node Vi 
is given by: 

(2011) in which TextRank and degree centrality are compared. However, both works were evalu- 

CD(Vi) = ||?|(Vi)| V ?1 

(1) 

ated against a summarization dataset by checking whether extracted keyphrases appear in reference summaries. This methodology is somewhat unre- liable, as a word that occurs in a summary is not necessarily a keyphrase (e.g. experiments, results). 
  
Closeness centrality is defined as the inverse 
of farness, i.e. the sum of the shortest distances between a node and all the other nodes. Let 
distance(Vi, Vj) be the shortest distance be- 
tween nodes Vi and Vj (in our case, computed us- 
ing inverted edge weights to use co-occurrence in- 
formation), the closeness centrality of a node Vi is 

3	Keyphrase extraction 	given by: 

                                                                   |V| ? 1 
                                                                   
Extracting keyphrases from a document can be di- 
vided into three steps. First, a word graph is con- 

CC(Vi) = 

Vj?V distance(Vi, Vj) 

(2) 

structed from the document. The importance of each word is then determined using a centrality measure. Lastly, keyphrase candidates are gen- erated and ranked based on the words they con- tain. The following sections describe each of these steps in detail. 
  
Betweenness centrality quantifies the number 
of times a node acts as a bridge along the shortest 
path between two other nodes. Let ?(Vj, Vk) be 
the number of shortest paths from node Vj to node 
Vk, and ?(Vj, Vk|Vi) the number of those paths 
that pass through node Vi. The betweenness cen- 
trality of a node Vi is given by: 

3.1 

Graph construction 



Vi=Vj=Vk?V 


?(Vj,Vk|Vi) 
 ?(Vj,Vk) 
 
Given a document, the first step consists in build- 
ing a graph representation from its content. An 

CB ( V i ) = 

(|V| ? 1)(|V| ? 2)/2 

(3) 

undirected word graph is constructed for each doc- ument, in which nodes are words and edges repre- sent co-occurrence relations within a window of maximum N words. Words added to the graph are restricted with syntactic filters, which select only lexical units of a certain Part-of-Speech (nouns and adjectives). Edges are weighted according to the co-occurrence count of the words they connect. Following (Wan and Xiao, 2008b), we set the co- 
  
Eigenvector centrality measures the central- 
ity of a node as a function of the centralities of its neighbors. Unlike degree, it accounts for the notion that connections to high-scoring nodes are more important than those to low-scoring ones. 
Let wji be the weight of the edge between nodes 
Vj and Vi and ? a constant, the eigenvector cen- 
trality of a node Vi is given by: 

occurrence window size to 10 in all our experi- ments. 

CE(Vi) = 1 


? V??? (V ) wji?? CE(Vj) 

(4) 

j

i


  TextRank is based on the eigenvector centrality 
measure and implements the concept of "voting". Let d be a damping factor (set to 0.85 as in (Mihal- 
cea and Tarau, 2004)), the TextRank score S(Vi) 
of a node Vi is initialized to a default value and 
computed iteratively until convergence using the 
following equation: 


                          wji?? S(Vj) 
  
The DEFT dataset (Paroubek et al., 2012) is 
made of French scientific articles published in so- cial science journals. We use the 93 articles of the test set and its set of author-assigned keyphrases. 


      Inspec Semeval DEFT 
    Type abstracts articles articles 
          Language English English French 
          
S(Vi) = (1?d)+ d??


Vj?? (Vi) V??? (V ) 

wjk 

(5) 
     
Documents 500 
Tokens/document 136 
 
100 
5180 
 
93 
6970 


3.3 


Keyphrase selection 

k

j

Keyphrases/document 9.8 
   Tokens/keyphrase 2.3 

14.7 
2.1 

5.2 
1.6 

Selecting keyphrases is a two step process. First, 
keyphrase candidates are extracted from the doc- ument. Sequences of adjacent words, restricted to nouns and adjectives only, are considered as candi- 

Table 1: Overview of the three datasets we use in 
our experiments. 

dates. Extracting sequences of adjacent words in- 	4.2 	Pre-processing 

stead of n-grams ensure that keyphrase candidates are grammatically correct but entail a lower recall. 
  The score of a candidate keyphrase k is com- 
puted by summing the scores of the words it con- tains normalized by its length + 1 to favor longer n-grams (see equation 6). 

For each dataset, we apply the following pre- 
processing steps: sentence segmentation, tokeni- sation and Part-of-Speech tagging. For the lat- ter, we use the Stanford POS-tagger (Toutanova et al., 2003) for English and MElt (Denis and Sagot, 2009) for French. We use the networkx2 package to compute the centrality measures. 

score(k) = 

word?k Score(word) 
 length(k) + 1 

(6) 


4.3 


Evaluation measures 


  Keyphrase candidates are then ranked and re- dundant candidates filtered out. Two candidates are considered redundant if they have a same stemmed form (e.g. "precisions" and "precision" are both stemmed to "precis"). 

The performance of each centrality measure is 
evaluated with precision, recall and f-score at the top 10 keyphrases. Candidate and reference keyphrases are stemmed to reduce the number of mismatches. Consistent with (Hasan and Ng, 2010), we also report the performance of each cen- trality measure in terms of precision-recall curves 

4

4.1 

Experimental settings 

 Datasets 

for the three datasets. To generate the curves, we vary the number of extracted keyphrases from 1 to the total number of keyphrase candidates. 

As mentioned by (Hasan and Ng, 2010), it is 
essential to evaluate keyphrase extraction meth- ods on multiple datasets to fully understand their 

5

Results 

strengths and weaknesses. Accordingly, we use three different datasets in our experiments. An overview of each dataset is given in Table 1. 
  The Inspec dataset (Hulth, 2003) is a collection 
of abstracts from journal papers. We use the 500 abstracts designated as the test set and the set of uncontrolled keyphrases. 
  The Semeval dataset (Kim et al., 2010) is 
composed of scientific articles collected from the ACM Digital Library. We use the 100 articles of the test set and its set of combined author- and reader-assigned keyphrases. 

Table 2 presents the performance of each central- 
ity measure on the three datasets. Overall, we ob- serve that the best results are obtained using de- gree which is the simplest centrality measure both conceptually and computationally. Closeness ob- tains the best results on Inspec and significantly outperforms TextRank. However, it yields the worst performance on the other two datasets. This suggests that closeness is best suited for short doc- uments (Inspec documents are 136 tokens long on average). 

     2http://networkx.github.io/ 
   
   
                 Inspec 	Semeval 	DEFT 
Centrality 
              P	R	F	P	R	F	P	R	F
Degree 	31.4 	37.6 	32.2 11.4 	8.0 	9.3 	7.7 	14.8 	10.0 
Closeness 	32.8?	38.6?	33.3 4.1 	2.8 	3.3 	2.6 	5.2 	3.4 Betweenness 	31.5 	37.7 	32.3 10.0 	7.1 	8.2 	7.3 	13.9 	9.5 Eigenvector 	29.5 	35.0 	30.2 10.7 	7.4 	8.7 	6.2 	12.1 	8.1 
TextRank 	31.5 	37.7 	32.2 	10.7 	7.4 	8.7 	7.6 	14.5 	9.9 

Table 2: Performance of each centrality measure in terms of precision, recall and f-score at the top 10 keyphrases on the three datasets ( and? indicate a significant improvement over TextRank at the 0.05 and 0.01 levels respectively using Student's t-test). 


50 


40 


30 


20 


10 



Closeness 
Degree 
Eigenvector 
TextRank 
Betweenness 

F=0.40 

F=0.30 

F=0.20 

F=0.10 


25 


20 


15 


10 


 5
 

 
Closeness 
Degree 
Eigenvector 
TextRank 
Betweenness 


F=0.20 


F=0.10 


25 


20 


15 


10 


 5
 

 
Closeness 
Degree 
Eigenvector 
TextRank 
Betweenness 


F=0.20 


F=0.10 


00 


10 20 


30 40 


50 


60 


70 


80 


00 


10 20 


30 40 


50 


60 


70 


80 


00 


10 20 


30 40 


50 


60 


70 


80 

  Recall (%) 
(a) Inspec 
   
Recall (%) 
(b) Semeval 
  
Recall (%) 
(c) DEFT 


Figure 1: Precision-recall curves for each centrality measure on the three datasets. 


  To get a better understanding of the perfor- 	6	Conclusion 
mance for each centrality measure, we report in 

Figure 1 their precision-recall curves for each of the three datasets. Moreover, to estimate how each measure performs in terms of f-score, we also plot the curves corresponding to different levels of f- score. Again, we observe that the best measure for the Inspec dataset is closeness. For the other two datasets, there is no centrality measure which overall performs best. We note that the maximum 
recall is almost the same for the three datasets. 





  Interestingly, degree and TextRank achieve sim- ilar performance on the three datasets. The reason for this is that TextRank is derived from PageR- ank which was shown to be proportional to the de- gree distribution for undirected graphs (Grolmusz, 2012). Degree centrality, whose time complex- ity is ?(V2), can therefore advantageously replace TextRank for keyphrase extraction. 

In this paper, we presented a comparison of five 
centrality measures for graph-based keyphrase ex- traction. Using three standard datasets of differ- ent languages and domains, we showed that de- gree centrality, despite being conceptually the sim- plest measure, achieves results comparable to the widely used TextRank algorithm. Moreover, re- sults show that closeness significantly outperforms the other centrality measures on short documents. 


Acknowledgments 

The author would like to thank Emmanuel Morin and Solen Quiniou for their helpful comments on this work. We also thank the anonymous re- viewers for their useful comments. This work was supported by the French Agence Nationale de la Recherche under grant ANR-12-CORD-0029 (TermITH project). 


References 
Pascal Denis and Benoit Sagot. 2009. Coupling an 
annotated corpus and a morphosyntactic lexicon for state-of-the-art pos tagging with less human effort. In Proceedings of PACLIC 2009, pages 110-119. 
Vince Grolmusz. 2012. A note on the pagerank of 
  undirected graphs. CoRR, abs/1205.1960. 
Juhyun Han, Taehwan Kim, and Joongmin Choi. 
2007. Web document clustering by using auto- matic keyphrase extraction. In Proceedings of the 
2007 IEEE/WIC/ACM International Conferences on 
Web Intelligence and Intelligent Agent Technology - 

Rada Mihalcea and Paul Tarau. 2004. Textrank: 
Bringing order into texts. In Proceedings of EMNLP 2004, pages 404-411. 
Tore Opsahl, Filip Agneessens, and John Skvoretz. 
2010. Node centrality in weighted networks: Gener- alizing degree and shortest paths. Social Networks, 32(3):245-251. 
Lawrence Page, Sergey Brin, Rajeev Motwani, and 
Terry Winograd. 1999. The pagerank citation rank- ing: bringing order to the web. 
Patrick Paroubek, Pierre Zweigenbaum, Dominic For- 
  est, and Cyril Grouin. 2012. Indexation libre 
  
Workshops, pages 56-59. 

et contr ´ d'articles scientifiques. Pr´ 

olee 

esentation et 

Kazi Saidul Hasan and Vincent Ng. 2010. Conun- 

r´ esultats du d´ fouille de textes DEFT2012. In Pro- efi 

drums in unsupervised keyphrase extraction: Mak- ing sense of the state-of-the-art. In Proceedings of COLING 2010: Posters, pages 365-373. 
Anette Hulth. 2003. Improved automatic keyword ex- 
traction given more linguistic knowledge. In Pro- ceedings of EMNLP 2003, pages 216-223. 
Steve Jones and Mark S. Staveley. 1999. Phrasier: 
a system for interactive document retrieval using keyphrases. In Proceedings of SIGIR 1999, pages 160-167. 
Su Nam Kim, Olena Medelyan, Min-Yen Kan, and 
  Timothy Baldwin. 2010. Semeval-2010 task 5 : Au- 
  
ceedings of the DEfi Fouille de Textes 2012 Work- ´
  shop, pages 1-13. 
Takashi Tomokiyo and Matthew Hurst. 2003. A lan- 
guage model approach to keyphrase extraction. In 
Proceedings of the ACL 2003 Workshop on Multi- 
word Expressions: Analysis, Acquisition and Treat- 
ment, pages 33-40. 
Kristina Toutanova, Dan Klein, Christopher D. Man- 
ning, and Yoram Singer. 2003. Feature-rich part-of- speech tagging with a cyclic dependency network. In Proceedings of NAACL 2003, pages 173-180. 
George Tsatsaronis, Iraklis Varlamis, and Kjetil 

tomatic keyphrase extraction from scientific articles. 
In Proceedings of the 5th International Workshop on Semantic Evaluation, pages 21-26. 

Nørv° ag. 2010. Semanticrank: Ranking keywords and sentences using semantic graphs. In Proceed- ings of COLING 2010, pages 1074-1082. 

Jon M. Kleinberg. 1999. Authoritative sources in 

Xiaojun Wan and Jianguo Xiao. 

2008a. 

Col- 

a hyperlinked environment. Journal of the ACM, 
46(5):604-632. 
Weiming Liang, Chang-Ning Huang, Mu Li, and Bao- 
Liang Lu. 2009. Extracting keyphrases from chi- nese news articles using textrank and query log knowledge. In Proceedings of PACLIC 2009, pages 733-740. 

labrank: Towards a collaborative approach to single- document keyphrase extraction. In Proceedings of COLING 2008, pages 969-976. 
Xiaojun Wan and Jianguo Xiao. 2008b. Single 
document keyphrase extraction using neighborhood knowledge. In Proceedings of the 23rd national conference on Artificial intelligence, AAAI'08, 

Marina Litvak and Mark Last. 

2008. 

Graph- 

pages 855-860. 

based keyword extraction for single-document sum- marization. In Proceedings of the Workshop on 
Multi-source Multilingual Information Extraction 
and Summarization, pages 17-24. 
Marina Litvak, Mark Last, Hen Aizenman, Inbal Go- 
bits, and Abraham Kandel. 2011. DegExt - A Language-Independent Graph-Based Keyphrase Ex- tractor. In Advances in Intelligent Web Mastering, pages 121-130. Springer. 
Zhiyuan Liu, Peng Li, Yabin Zheng, and Maosong 
Sun. 2009. Clustering to find exemplar terms for keyphrase extraction. In Proceedings of EMNLP 2009, pages 257-266. 
Zhiyuan Liu, Wenyi Huang, Yabin Zheng, and 
Maosong Sun. 2010. Automatic keyphrase extrac- tion via topic decomposition. In Proceedings of EMNLP 2010, pages 366-376. 

Ian H. Witten, Gordon W. Paynter, Eibe Frank, Carl 
Gutwin, and Craig G. Nevill-Manning. 1999. Kea: practical automatic keyphrase extraction. In Pro- 
ceedings of the fourth ACM conference on Digital 
libraries, pages 254-255. 
Hongyuan Zha. 2002. Generic summarization and 
keyphrase extraction using mutual reinforcement principle and sentence clustering. In Proceedings of SIGIR 2002, pages 113-120. 

